---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Welcome to my homepage!
I am a second-year Computer Science student at Brown University <img src='./images/brown.jepg' style="width: 1.35em;">, working on multimodal learning, Vision-Language Models (VLMs), and Large Vision-Language Models (LVLMs).

# ğŸ”¥ News
- *2025.11*: &nbsp;ğŸ‰ğŸ‰ Two papers are accepted at AAAI 2026 and both are selected as Oral presentationsğŸ…! See you in Singapore!
- *2025.11*: &nbsp;ğŸ‰ğŸ‰ Three papers are accepted at WACV 2026!
- *2025.09*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted at NeurIPS 2025!
- *2025.08*: &nbsp;ğŸ‰ğŸ‰ Three papers are accepted at EMNLP 2025 (two at the Main conference and one at Findings)! One of them is selected as an Oral presentationğŸ…! See you in Suzhou!
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted at COLM 2025! See you in Montreal!
- *2025.07*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted at ACM MM 2025!
- *2025.05*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted at ICML 2025!
- *2025.01*: &nbsp;ğŸ‰ğŸ‰ Two papers are accepted at ICLR 2025 Workshop and both are selected as Oral presentationsğŸ…! See you in Singapore!
- *2024.09*: &nbsp;ğŸ”ğŸ” I join Brown University as a Masterâ€™s student in Computer Science!
- *2024.09*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted at NeurIPS 2024!
# ğŸ“ Publications 
**For a complete list of publications, please visit my [Google Scholar](https://scholar.google.com/citations?user=eTzFWiUAAAAJ&hl=en)**.
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2026 Oral</div><img src='images/CAMA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CAMA: Enhancing Multimodal In-Context Learning with Context-Aware
Modulated Attention](https://arxiv.org/abs/2505.17097)

**Yanshu Li**, Jianjiang Yang, Ziteng Yang, Bozheng Li, Hongyang He, Zhengtao Yao, Ligong Han, Yingjie Victor Chen, Songlin Fei, Dongfang Liu, Ruixiang Tang
- We propose Context-Aware Modulated Attention (CAMA), a training-free method that dynamically adjusts attention logits to fix attention deficits in LVLMs' multimodal in-context learning. This work improves model stability, reduces erroneous attention patterns, and enhances the consistency of multimodal reasoning.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2026 Oral</div><img src='images/CATP.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced
Multimodal In-Context Learning](https://arxiv.org/abs/2508.07871)

**Yanshu Li***, Jianjiang Yang*, Zhennan Shen, Ligong Han, Haoyan Xu, Ruixiang Tang
- We propose Contextually Adaptive Token Pruning (CATP), a training-free image token pruning method that adapts to complex image-text interactions and significantly reduces redundant image tokens in LVLMs. This research pushes forward the efficiency and practical applicability of multimodal in-context learning.
</div>
</div>
# ğŸ“– Educations
- *2024.9 - 2026.5 (Expected)*, Master's in Computer Science, Brown University, Providence, Rhode Island, USA. Advised by [Ellie Pavlick](https://cs.brown.edu/people/epavlick/).
- *2025.1 - present*, Research Internship, Rutgers University, New Brunswick, New Jersey, USA. Advised by [Ruixiang Tang](https://www.ruixiangtang.net/).
- *2020.9 - 2024.6*, Bachelor in Artificial Intelligence, Soochow University, Suzhou, Jiangsu, China. Advised by [Juntao Li](https://lijuntaopku.github.io/).

# ğŸ’» Industrial Internships
- *2024.04-2024.06*, Foundation Model Engineer, [Baidu](https://en.wikipedia.org/wiki/Baidu), Shanghai, China
- *2023.10-2024.02*, Foundation Model Engineer, [iFlytek](https://www.iflytek.com/en/), Suzhou, China

# âš™ï¸ Services
- *Volunteer*: COLM 2024, COLM 2025, ICLR 2025, EMNLP 2025
- *Reviewer*: ARR Feb/May/Jul/Oct 2025, COLM 2025, NeurIPS 2025, AAAI 2026, ICLR 2026

